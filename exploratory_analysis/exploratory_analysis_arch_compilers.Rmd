---
title: "Analisis Proyecto"
author:
- 'Estudiante 1: Archibald Carrion'
- 'Estudiante 2: Milton Sojo'
- 'Estudiante 3: Brandon Trigueros'
- 'Estudiante 4: David Gonzalez'
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: '2'
    df_print: paged
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
subtitle: "CI0131 - Diseño de Experimentos I Ciclo 2025"
header-includes:
- \usepackage{float}
- \floatplacement{figure}{H}
editor_options:
  markdown:
    wrap: 72
---

```{r configuracion, warning=FALSE}
# Configuración inicial del documento
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Preparación de datos

En esta sección se preparan los datos para el análisis: cargamos las
bibliotecas necesarias, importamos el archivo CSV y configuramos las
variables del experimento.

```{r cargar_librerias, warning=FALSE}
# Carga de librerías necesarias para el análisis
library(dplyr)
library(ggplot2)
library(readr)
```

```{r importar_datos, warning=FALSE}
# Lectura del archivo CSV con los resultados del benchmark
df = (read.csv("../data/execution/combined_data.csv", header=T, encoding = "UTF-8"))

# Renombra y convierte variables
df <- df %>%
  mutate(
    response    = avg_time_sec,
    architecture= factor(architecture, levels = c("intel","ryzen")),
    compiler    = factor(compiler,   levels = c("clang","gcc")),
    obs         = row_number()           # índice de observación
  )
```

## Aleatorización de datos

Para garantizar la validez del análisis, aleatorizamos el orden de las
observaciones para evitar efectos sistemáticos relacionados con el
momento en que se tomaron las mediciones.

```{r aleatorizacion_datos, warning=FALSE}
# Barajamos todo el dataframe para aleatorización real
set.seed(1234)
df <- df %>%
  sample_frac(1) %>%           # baraja todas las filas
  mutate(
    obs           = row_number(),            # índice de observación aleatorio
    time_observed = cumsum(response)         # tiempo acumulado desde t0 = 0
  )
```

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

Visualización de las primeras filas del dataframe después de la
aleatorización:

```{r mostrar_datos, warning=FALSE}
# Muestra las primeras filas del dataframe aleatorizado
head(df)
```

## Estadísticas descriptivas globales

Calculamos estadísticas básicas para toda la muestra para entender la
distribución general de los tiempos de ejecución.

```{r estadisticas_globales, warning=FALSE}
# Cálculo de medidas estadísticas básicas para toda la muestra
global_stats <- df %>%
  summarise(
    mean    = mean(response),
    variance= var(response),
    sd      = sd(response),
    min     = min(response),
    Q1      = quantile(response, 0.25),
    median  = median(response),
    Q3      = quantile(response, 0.75),
    max     = max(response)
  )

print(global_stats)
```

Las estadísticas muestran la distribución de los tiempos de ejecución en
la muestra completa, observándose un tiempo medio de ejecución de
`r round(global_stats$mean, 4)` segundos con una desviación estándar de
`r round(global_stats$sd, 4)` segundos.

-   **Media**: ∼0.022 s, pero la **mediana** es mucho menor (∼0.009 s),
    lo que señala una cola larga de valores grandes.

<!-- -->

-    El **mínimo negativo** (−0.050 s) es un artefacto de medición o un
    error que habría que depurar.

<!-- -->

-    El **IQR** (desde Q1 hasta Q3) cubre valores muy bajos (1–10 ms),
    mostrando que la mayoría de corridas son ultrarrápidas.

## Visualizaciones exploratorias globales

### Boxplot de tiempos de ejecución

El siguiente boxplot muestra la distribución general de los tiempos de
ejecución utilizando una escala logarítmica para manejar los outliers.

```{r boxplot_global, warning=FALSE}
# Boxplot global con escala logarítmica
ggplot(df, aes(y = response)) +
  geom_boxplot() +
  scale_y_log10() +  # Escala logarítmica para mejor visualización
  labs(
    title = "Boxplot de la variable de respuesta (escala logarítmica)",
    y     = "Tiempo medio de ejecución (s) [log10]"
  )
```

-   La **caja** se extiende aproximadamente de 10⁻³ s a 10⁻² s, con
    mediana en ∼3×10⁻³ s.

-   Los **bigotes** llegan hasta unos 10⁻¹ s; todo punto por encima se
    marca como “outlier”, revelando ejecuciones muy lentas (hasta 2.6
    s).

-   La escala logarítmica permite comprimir la cola y visualizar bien la
    distribución central.

### Histograma de tiempos de ejecución

El histograma permite visualizar la distribución de frecuencias de los
tiempos de ejecución usando escala logarítmica.

```{r histograma_global, warning=FALSE}
# Histograma con escala logarítmica
ggplot(df, aes(x = response)) +
  geom_histogram(bins = 50, color = "black", fill = "lightgray") +
  scale_x_log10() +  # Escala logarítmica para mejor visualización
  labs(
    title = "Histograma de la variable de respuesta (escala logarítmica)",
    x     = "Tiempo medio de ejecución (s) [log10]",
    y     = "Frecuencia"
  ) +
  theme_minimal()
```

**Distribución fuertemente sesgada:**

Pico con más frecuencia en la zona de 10⁻³–10⁻² s.

Caída rápida hacia tiempos más largos, con una larga cola de bajas
frecuencias hasta ∼10⁰ s.

El histograma confirma visualmente esa asimetría y la presencia de
valores extremos.

**Gráfico comparativo por compilador:**

```{r}
library(ggplot2)

# Interacción: Media de response por compilador, coloreado por arquitectura
ggplot(df, aes(x = compiler, y = response, color = architecture, group = architecture)) +
  stat_summary(fun = mean, geom = "point", size = 3) +
  stat_summary(fun = mean, geom = "line", size = 1) +
  labs(
    title = "Interacción: Media de avg_time_sec por Compilador",
    x     = "Compilador",
    y     = "Tiempo medio de ejecución (s)",
    color = "Arquitectura"
  ) +
  theme_minimal()

```

**Gráfico comparativo por arquitectura:**

```{r}
# Interacción: Media de response por arquitectura, coloreado por compilador
ggplot(df, aes(x = architecture, y = response, color = compiler, group = compiler)) +
  stat_summary(fun = mean, geom = "point", size = 3) +
  stat_summary(fun = mean, geom = "line", size = 1) +
  labs(
    title = "Interacción: Media de avg_time_sec por Arquitectura",
    x     = "Arquitectura",
    y     = "Tiempo medio de ejecución (s)",
    color = "Compilador"
  ) +
  theme_minimal()
```

Indica que los efectos de los factores son **consistentes** a través de
los niveles del otro factor

### Creación de variable de tratamiento

Para análisis posterior, creamos una variable que combine arquitectura y
compilador.

```{r crear_tratamiento, warning=FALSE}
# Creamos la variable treatment para usarla en los gráficos
df <- df %>%
  mutate(treatment = interaction(architecture, compiler, sep = " × "))
```

### Serie temporal de mediciones

Este gráfico muestra cómo varían los tiempos de ejecución a lo largo del
tiempo observado, diferenciando por tratamiento.

```{r serie_temporal, warning=FALSE}
# Serie temporal de tiempos de ejecución
ggplot(df, aes(x = time_observed, y = response, color = treatment)) +
  geom_point(size = 1, alpha = 0.6) +
  scale_color_brewer(palette = "Dark2") +
  scale_y_log10() +
  labs(
    title = "Serie temporal de avg_time_sec vs. tiempo observado",
    x     = "Tiempo observado (s)",
    y     = "Tiempo medio de ejecución (s) [log10]",
    color = "Tratamiento"
  ) +
  theme_minimal()
```

**Cada punto es una corrida coloreada por tratamiento.**

**Se observa claramente la separación horizontal:**

Intel siempre entre ∼10⁻³ y 10⁻² s.

Ryzen entre ∼10⁻² y 10⁻¹ s (o más).

Esto refleja el efecto real de arquitectura sobre el rendimiento, no un
fallo de aleatorización.

### Verificación de aleatorización

Este gráfico permite verificar que la aleatorización ha funcionado
correctamente, mostrando la distribución de tratamientos en el orden de
observación.

```{r verificar_aleatorizacion, warning=FALSE}
# Gráfico para verificar la aleatorización
ggplot(df, aes(x = obs, y = treatment)) +
  geom_tile(fill = "steelblue") +
  labs(
    title = "Orden de tratamientos tras aleatorizar",
    x     = "Índice de observación",
    y     = "Tratamiento"
  ) +
  theme_minimal()
```

Para verificar la aleatorización generamos un gráfico de “rayas” en el
que cada raya vertical representa una corrida. Si la aleatorización
fuese deficiente, veríamos bloques de un solo tratamiento juntos (por
ejemplo, todas las corridas de intel×clang seguidas, luego las de
ryzen×gcc, etc.).

En nuestro plot, cada uno de los cuatro tratamientos aparece disperso a
lo largo de todo el eje-X, sin concentrarse en ningún tramo específico.
Esto demuestra que hemos mezclado ("barajado") correctamente el orden de
las corridas antes de tomarlas.

-   El gráfico de “rayas” muestra cada tratamiento repartido de modo
    uniforme sobre el eje X (índice de observación).

-   No hay bloques continuos de un solo color: cada uno de los cuatro
    tratamientos aparece intercalado a lo largo de todo el rango, lo que
    confirma que el orden está bien aleatorizado.

## Análisis por factores individuales

### Estadísticas por arquitectura

Analizamos las diferencias en tiempos de ejecución entre las
arquitecturas Intel y Ryzen.

```{r estadisticas_por_arquitectura, warning=FALSE}
# Estadísticas descriptivas agrupadas por tipo de arquitectura
arch_stats <- df %>%
  group_by(architecture) %>%
  summarise(
    n       = n(),
    mean    = mean(response),
    variance= var(response),
    sd      = sd(response),
    min     = min(response),
    Q1      = quantile(response, 0.25),
    median  = median(response),
    Q3      = quantile(response, 0.75),
    max     = max(response)
  )
print(arch_stats)
```

Las estadísticas muestran diferencias en el rendimiento medio entre las
arquitecturas Intel y Ryzen, con Intel mostrando un tiempo medio de
`r round(arch_stats$mean[1], 4)` segundos frente a Ryzen con
`r round(arch_stats$mean[2], 4)` segundos.

-   Intel es, de media, **∼2.3× más rápido** que Ryzen.

-   La variabilidad (sd) también es menor en Intel, indicando
    ejecuciones más consistentes.

### Estadísticas por compilador

Comparamos el rendimiento entre los compiladores GCC y Clang.

```{r estadisticas_por_compilador, warning=FALSE}
# Estadísticas descriptivas agrupadas por tipo de compilador
comp_stats <- df %>%
  group_by(compiler) %>%
  summarise(
    n       = n(),
    mean    = mean(response),
    variance= var(response),
    sd      = sd(response),
    min     = min(response),
    Q1      = quantile(response, 0.25),
    median  = median(response),
    Q3      = quantile(response, 0.75),
    max     = max(response)
  )
print(comp_stats)
```

Los resultados muestran diferencias en el rendimiento entre los
compiladores, con Clang mostrando un tiempo medio de
`r round(comp_stats$mean[1], 4)` segundos frente a GCC con
`r round(comp_stats$mean[2], 4)` segundos.

**Clang rinde ligeramente mejor (∼11% más rápido en media) y con menor
dispersión.**

## Análisis de interacciones entre factores

Examinamos cómo interactúan la arquitectura y el compilador.

```{r estadisticas_combinadas, warning=FALSE}
# Estadísticas por combinación de factores
treat_stats <- df %>%
  group_by(architecture, compiler) %>%
  summarise(
    n       = n(),
    mean    = mean(response),
    variance= var(response),
    sd      = sd(response),
    min     = min(response),
    Q1      = quantile(response, 0.25),
    median  = median(response),
    Q3      = quantile(response, 0.75),
    max     = max(response)
  )
print(treat_stats)
```

El análisis combinado revela cómo cada compilador rinde en cada
arquitectura, mostrando posibles interacciones entre estos factores.

-   Dentro de cada arquitectura, Clang siempre supera a GCC.

-   La diferencia absoluta entre compiladores es menor en Intel (0.0024
    s) que en Ryzen (0.0030 s), sugiriendo una interacción débil.

## Visualizaciones comparativas

### Comparación por arquitectura

```{r boxplot_arquitectura, warning=FALSE}
# Boxplot comparativo por arquitectura
ggplot(df, aes(x = architecture, y = response, fill = architecture)) +
  geom_boxplot(alpha = 0.7) +
  scale_y_log10() +
  scale_fill_brewer(palette = "Set1") +
  labs(
    title = "Tiempo de ejecución por Arquitectura",
    subtitle = "Escala logarítmica para mejor visualización",
    x = "Arquitectura",
    y = "Tiempo medio de ejecución (s) [log10]"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "none"
  )
```

El boxplot muestra visualmente las diferencias en distribución y
variabilidad de los tiempos de ejecución entre las arquitecturas Intel y
Ryzen.

-   En escala logarítmica, Intel muestra una caja muy compacta alrededor
    de 10⁻³ s, mientras que la de Ryzen está desplazada hacia 10⁻² s y
    es más ancha, confirmando diferencias tanto en posición como en
    dispersión

### Comparación por compilador

```{r boxplot_compilador, warning=FALSE}
# Boxplot comparativo por compilador
ggplot(df, aes(x = compiler, y = response, fill = compiler)) +
  geom_boxplot(alpha = 0.7) +
  scale_y_log10() +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = "Tiempo de ejecución por Compilador",
    subtitle = "Escala logarítmica para mejor visualización",
    x = "Compilador",
    y = "Tiempo medio de ejecución (s) [log10]"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "none"
  )
```

Este boxplot permite visualizar las diferencias de rendimiento entre los
compiladores Clang y GCC.

-   Ambos compiladores dejan cajas centradas en ∼10⁻² s, pero la de GCC
    es un poco más ancha y su mediana se sitúa ligeramente por debajo de
    Clang, reflejando la media y varianza anteriores.

### Comparación de todos los tratamientos

Finalmente, comparamos el rendimiento de todas las combinaciones de
arquitectura y compilador.

```{r visualizacion_tratamientos, warning=FALSE}
# Boxplot comparativo de todos los tratamientos
ggplot(df, aes(x = treatment, y = response, fill = treatment)) +
  geom_boxplot(alpha = 0.7) +
  scale_y_log10() +
  scale_fill_brewer(palette = "Dark2") +
  labs(
    title = "Comparación de Tratamientos (Arquitectura × Compilador)",
    subtitle = "Análisis de tiempos de ejecución en escala logarítmica",
    x = "Tratamiento",
    y = "Tiempo medio de ejecución (s) [log10]"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )
```

Este gráfico permite visualizar y comparar el rendimiento de cada
combinación específica de arquitectura y compilador, revelando patrones
que pueden no ser evidentes al analizar cada factor por separado.

**Se observa el orden de rendimiento de más rápido a más lento:**

1.  intel×clang (menor mediana)

2.  intel×gcc

3.  ryzen×clang

4.  ryzen×gcc (mayor mediana y dispersión)

Esta vista conjunta resalta cómo la combinación de factores impacta el
tiempo de ejecución y permite planificar optimizaciones.
